{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYQxRWGHVOfu"
   },
   "source": [
    "<img src=\"https://2.bp.blogspot.com/-066qpJs0Ttc/WiYPXGNYEYI/AAAAAAAAFu8/XbOaf7DqfDMM9truu3DkrkIGfRgP4zBzgCLcBGAs/s1600/udinus.jpg\"  width=\"200\">\n",
    "\n",
    "# AMS - 11 - Document Similarity\n",
    "\n",
    "oleh: Dr. Eng. Farrikh Alzami M.Kom; Abu Salam, M.Kom\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5c9r2AZFeRP"
   },
   "source": [
    "# Rekomendasi Film dengan Kemiripan Dokumen\n",
    "\n",
    "Sistem rekomendasi adalah salah satu aplikasi pembelajaran mesin yang populer dan paling banyak diadopsi. Mereka biasanya digunakan untuk merekomendasikan entitas kepada pengguna dan entitas ini dapat berupa apa saja seperti produk, film, layanan, dan sebagainya.\n",
    "\n",
    "Contoh rekomendasi yang populer meliputi,\n",
    "- Amazon menyarankan produk di situs webnya\n",
    "- Amazon Prime, Netflix, Hotstar merekomendasikan film\\acara\n",
    "- YouTube merekomendasikan video untuk ditonton\n",
    "\n",
    "Biasanya sistem pemberi rekomendasi dapat diimplementasikan dalam tiga cara:\n",
    "\n",
    "- Simple Rule-based Recommenders / Rekomendasi Berbasis Aturan Sederhana: Biasanya berdasarkan metrik dan ambang batas global tertentu seperti popularitas film, peringkat global, dll.\n",
    "- Content-based Recommenders / Rekomendasi berbasis konten: Ini didasarkan pada penyediaan entitas serupa berdasarkan entitas minat tertentu. Metadata konten dapat digunakan di sini seperti deskripsi film, genre, pemeran, sutradara, dan sebagainya\n",
    "- Collaborative filtering Recommenders / Pemfilteran kolaboratif Rekomendasi: Di ​​sini kami tidak memerlukan metadata, tetapi kami mencoba memprediksi rekomendasi dan peringkat berdasarkan peringkat sebelumnya dari berbagai pengguna dan item tertentu.\n",
    "\n",
    "Kami akan membangun sistem rekomendasi film di sini berdasarkan data\\metadata yang berkaitan dengan film yang berbeda, kami mencoba dan merekomendasikan film serupa yang menarik!\n",
    "\n",
    "![](https://i.imgur.com/c7Go7d3.png)\n",
    "\n",
    "Karena fokus kami bukan pada mesin rekomendasi tetapi NLP, kami akan memanfaatkan metadata berbasis teks untuk setiap film untuk mencoba dan merekomendasikan film serupa berdasarkan film tertentu yang diminati. Ini termasuk dalam rekomendasi berbasis konten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXftv7OSFsHJ"
   },
   "source": [
    "## install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14486,
     "status": "ok",
     "timestamp": 1668751364805,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "o9Ntmc0GVGIA",
    "outputId": "5a17bf3b-04ab-4bee-b74f-f8f817f84afe"
   },
   "outputs": [],
   "source": [
    "# !pip install textsearch\n",
    "# !pip install contractions\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/LENOVO/OneDrive/Documents/STKI/Minggu 4/Similarity')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "pathlib.Path().resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqkJZoc8Funn"
   },
   "source": [
    "## load dan view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2226,
     "status": "ok",
     "timestamp": 1668751387985,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "NmbIBH8YVLV_",
    "outputId": "cb7ac0d2-6f33-4ac4-b110-7fd1bd6ba85c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File tidak ditemukan! Periksa path berikut: C:/Users/LENOVO/Documents/STKI/Minggu 4/tmdb_5000_movies.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ganti path ini sesuai lokasi file CSV di komputermu\n",
    "file_path = r\"C:/Users/LENOVO/Documents/STKI/Minggu 4/tmdb_5000_movies.csv.gz\"\n",
    "\n",
    "# Cek apakah file ada\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_csv(file_path, compression='gzip')\n",
    "    print(\"File berhasil dibaca!\")\n",
    "    display(df.head())  # menampilkan 5 baris pertama\n",
    "else:\n",
    "    print(\"File tidak ditemukan! Periksa path berikut:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1668751398690,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "ibqw4SCJVWIO",
    "outputId": "9394c408-b65a-417c-c1b1-47dcb4d760cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidak ada file yang dipilih!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "Tk().withdraw()\n",
    "file_path = askopenfilename(title=\"Pilih file CSV\", filetypes=[(\"CSV files\", \"*.csv *.csv.gz\")])\n",
    "\n",
    "if file_path:\n",
    "    df = pd.read_csv(file_path, compression='gzip') if file_path.endswith(\".gz\") else pd.read_csv(file_path)\n",
    "    df = df[['title', 'tagline', 'overview', 'popularity']]\n",
    "    df['tagline'].fillna('', inplace=True)\n",
    "    df['description'] = df['tagline'].map(str) + ' ' + df['overview']\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sort_values(by=['popularity'], ascending=False)\n",
    "    df.info()\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"Tidak ada file yang dipilih!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1668751412816,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "jphrq6CGVYwh",
    "outputId": "6439c3b9-ce8c-4f76-e546-aec59c69611b"
   },
   "outputs": [],
   "source": [
    "df = df[['title', 'tagline', 'overview', 'popularity']]\n",
    "df.tagline.fillna('', inplace=True)\n",
    "df['description'] = df['tagline'].map(str) + ' ' + df['overview']\n",
    "df.dropna(inplace=True)\n",
    "df = df.sort_values(by=['popularity'], ascending=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1668751420462,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "EGttDhkyVcnN",
    "outputId": "f0559949-5d18-4728-d50b-6aeb8a912bf5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tagline</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Minions</td>\n",
       "      <td>Before Gru, they had a history of bad bosses</td>\n",
       "      <td>Minions Stuart, Kevin and Bob are recruited by...</td>\n",
       "      <td>875.581305</td>\n",
       "      <td>Before Gru, they had a history of bad bosses M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "      <td>Interstellar chronicles the adventures of a gr...</td>\n",
       "      <td>724.247784</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Deadpool</td>\n",
       "      <td>Witness the beginning of a happy ending</td>\n",
       "      <td>Deadpool tells the origin story of former Spec...</td>\n",
       "      <td>514.569956</td>\n",
       "      <td>Witness the beginning of a happy ending Deadpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>All heroes start somewhere.</td>\n",
       "      <td>Light years from Earth, 26 years after being a...</td>\n",
       "      <td>481.098624</td>\n",
       "      <td>All heroes start somewhere. Light years from E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>What a Lovely Day.</td>\n",
       "      <td>An apocalyptic story set in the furthest reach...</td>\n",
       "      <td>434.278564</td>\n",
       "      <td>What a Lovely Day. An apocalyptic story set in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  \\\n",
       "546                  Minions   \n",
       "95              Interstellar   \n",
       "788                 Deadpool   \n",
       "94   Guardians of the Galaxy   \n",
       "127       Mad Max: Fury Road   \n",
       "\n",
       "                                               tagline  \\\n",
       "546       Before Gru, they had a history of bad bosses   \n",
       "95   Mankind was born on Earth. It was never meant ...   \n",
       "788            Witness the beginning of a happy ending   \n",
       "94                         All heroes start somewhere.   \n",
       "127                                 What a Lovely Day.   \n",
       "\n",
       "                                              overview  popularity  \\\n",
       "546  Minions Stuart, Kevin and Bob are recruited by...  875.581305   \n",
       "95   Interstellar chronicles the adventures of a gr...  724.247784   \n",
       "788  Deadpool tells the origin story of former Spec...  514.569956   \n",
       "94   Light years from Earth, 26 years after being a...  481.098624   \n",
       "127  An apocalyptic story set in the furthest reach...  434.278564   \n",
       "\n",
       "                                           description  \n",
       "546  Before Gru, they had a history of bad bosses M...  \n",
       "95   Mankind was born on Earth. It was never meant ...  \n",
       "788  Witness the beginning of a happy ending Deadpo...  \n",
       "94   All heroes start somewhere. Light years from E...  \n",
       "127  What a Lovely Day. An apocalyptic story set in...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1668751465201,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "yXyKhbjKVeap",
    "outputId": "a5f02189-1090-4661-dfa5-a41c752a94a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before Gru, they had a history of bad bosses Minions Stuart, Kevin and Bob are recruited by Scarlet Overkill, a super-villain who, alongside her inventor husband Herb, hatches a plot to take over the world.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60vwITLaGCxO"
   },
   "source": [
    "# Bangun Sistem Rekomendasi Film\n",
    "\n",
    "Di sini Anda akan membangun sistem rekomendasi film Anda sendiri. Kami akan menggunakan pipa berikut:\n",
    "- Teks pra-pemrosesan\n",
    "- Rekayasa Fitur\n",
    "- Komputasi Kemiripan Dokumen\n",
    "- Temukan film serupa teratas\n",
    "- Bangun fungsi rekomendasi film\n",
    "\n",
    "\n",
    "## Kemiripan Dokumen / document similarity\n",
    "\n",
    "Rekomendasi adalah tentang memahami fitur dasar yang membuat kita menyukai satu pilihan daripada yang lain. Kesamaan antar item (dalam hal ini film) adalah salah satu cara untuk memahami mengapa kita memilih satu film daripada yang lain. Ada berbagai cara untuk menghitung kesamaan antara dua item. Salah satu ukuran yang paling banyak digunakan adalah __cosine similarity__ yang telah kita gunakan di unit sebelumnya.\n",
    "\n",
    "### Kemiripan Kosinus\n",
    "\n",
    "Cosine Similarity digunakan untuk menghitung skor numerik untuk menunjukkan kesamaan antara dua dokumen teks. Secara matematis, ini didefinisikan sebagai berikut:\n",
    "\n",
    "$$ cosinus(x,y) = \\frac{x. y^\\intercal}{||x||.||y||} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3582,
     "status": "ok",
     "timestamp": 1668751482462,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "jhmh3aAqVk9X",
    "outputId": "14d715b2-aace-4eba-cd92-fa4dce2a647c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    doc = contractions.fix(doc)\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    #filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['description']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Njr1PJAyGI3T"
   },
   "source": [
    "## Extrak TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1668751484503,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "q81rt1hlVs2l",
    "outputId": "966c8a65-19d5-473e-e1c9-b6248ce7c606"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 20471)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buWfXVACGMlI"
   },
   "source": [
    "## Compute Pairwise Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 1078,
     "status": "ok",
     "timestamp": 1668751490801,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "htSj1WBPVt3p",
    "outputId": "f6ad2633-877e-49cd-bff7-f7f90d5a06c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4792</th>\n",
       "      <th>4793</th>\n",
       "      <th>4794</th>\n",
       "      <th>4795</th>\n",
       "      <th>4796</th>\n",
       "      <th>4797</th>\n",
       "      <th>4798</th>\n",
       "      <th>4799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027126</td>\n",
       "      <td>0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060846</td>\n",
       "      <td>0.025039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036237</td>\n",
       "      <td>0.030516</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022064</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.036561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076033</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.043475</td>\n",
       "      <td>0.011465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5     6         7     \\\n",
       "0  1.000000  0.000000  0.000000  0.000000  0.006071  0.008067   0.0  0.000000   \n",
       "1  0.000000  1.000000  0.000000  0.017839  0.007968  0.000000   0.0  0.012501   \n",
       "2  0.000000  0.000000  1.000000  0.000000  0.017178  0.000000   0.0  0.000000   \n",
       "3  0.000000  0.017839  0.000000  1.000000  0.000000  0.022414   0.0  0.000000   \n",
       "4  0.006071  0.007968  0.017178  0.000000  1.000000  0.004673   0.0  0.064581   \n",
       "\n",
       "   8         9     ...      4790      4791      4792  4793      4794  \\\n",
       "0   0.0  0.000000  ...  0.018758  0.000000  0.037930   0.0  0.000000   \n",
       "1   0.0  0.014840  ...  0.000000  0.000000  0.017564   0.0  0.019152   \n",
       "2   0.0  0.024326  ...  0.000000  0.006903  0.005024   0.0  0.012893   \n",
       "3   0.0  0.037207  ...  0.000000  0.060846  0.025039   0.0  0.036237   \n",
       "4   0.0  0.000000  ...  0.022064  0.019662  0.036561   0.0  0.015826   \n",
       "\n",
       "       4795      4796      4797      4798      4799  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.009646  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.007963  \n",
       "2  0.000000  0.025975  0.000000  0.027126  0.009340  \n",
       "3  0.030516  0.022605  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.076033  0.004516  0.043475  0.011465  \n",
       "\n",
       "[5 rows x 4800 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06tyYXABGOY2"
   },
   "source": [
    "## mendapatkan title / judul movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1668751494332,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "AkQ1-OjFVvdw",
    "outputId": "2d58ea43-412b-4bc6-b132-d3d13a036092"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Minions', 'Interstellar', 'Deadpool', ..., 'Penitentiary',\n",
       "        'Alien Zone', 'America Is Still the Place'], dtype=object),\n",
       " (4800,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list = df['title'].values\n",
    "movies_list, movies_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYnMl5HVGY3v"
   },
   "source": [
    "## Temukan Film Serupa Teratas untuk Contoh Film\n",
    "\n",
    "Mari ambil __Minions__ film paling populer dari kerangka data di atas dan coba temukan film paling mirip yang dapat direkomendasikan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jb0zYhQGGdXs"
   },
   "source": [
    "### ambil movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668751497820,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "2-0eF9d5VwcD",
    "outputId": "d820533c-708d-4458-e725-c782a5c270ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_idx = np.where(movies_list == 'Minions')[0][0]\n",
    "movie_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5ANO-GxGg0D"
   },
   "source": [
    "### ambil similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668751504352,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "50qG66H4VxaO",
    "outputId": "05804a11-ac11-4536-9103-380d1eec0f4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "       0.00964646])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_similarities = doc_sim_df.iloc[movie_idx].values\n",
    "movie_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Z4U9XqMGofg"
   },
   "source": [
    "### Get top 5 similar movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1668751508133,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "nCp6LI9OVzBh",
    "outputId": "287a770a-34e1-4c38-9c7c-363bf5cb097a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33,  60, 737, 490, 298])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "similar_movie_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf3R8PL_GsFV"
   },
   "source": [
    "### Get top 5 similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1668751511982,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "p45bXWcLVz7V",
    "outputId": "89e1f3ac-2a16-44c7-8ef6-f174b1bc02cf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Pastikan df sudah terbentuk sebelumnya\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m movies_list = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m].tolist()\n\u001b[32m      3\u001b[39m similar_movie_idxs = [\u001b[32m2\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m15\u001b[39m]  \u001b[38;5;66;03m# contoh indeks film mirip\u001b[39;00m\n\u001b[32m      5\u001b[39m similar_movies = [movies_list[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m similar_movie_idxs]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "similar_movies = movies_list[similar_movie_idxs]\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsEr2msSG0P_"
   },
   "source": [
    "### Buat fungsi rekomendasi film untuk merekomendasikan 5 film serupa teratas untuk film apa pun\n",
    "\n",
    "\n",
    "The movie title, movie title list and document similarity matrix dataframe akan diberikan sebagai input ke fungsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ntQfhP_CV0wO"
   },
   "outputs": [],
   "source": [
    "def movie_recommender(movie_title, movies=movies_list, doc_sims=doc_sim_df):\n",
    "    # find movie id\n",
    "    movie_idx = np.where(movies == movie_title)[0][0]\n",
    "    # get movie similarities\n",
    "    movie_similarities = doc_sims.iloc[movie_idx].values\n",
    "    # get top 5 similar movie IDs\n",
    "    similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "    # get top 5 movies\n",
    "    similar_movies = movies[similar_movie_idxs]\n",
    "    # return the top 5 movies\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woWv4gI9G_j8"
   },
   "source": [
    "# misal cari rekomendasi untuk film film berikut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5tyK3sc9V1sW"
   },
   "outputs": [],
   "source": [
    "popular_movies = ['Minions', 'Interstellar', 'Deadpool', 'Jurassic World', 'Pirates of the Caribbean: The Curse of the Black Pearl',\n",
    "              'Dawn of the Planet of the Apes', 'The Hunger Games: Mockingjay - Part 1', 'Terminator Genisys', \n",
    "              'Captain America: Civil War', 'The Dark Knight', 'The Martian', 'Batman v Superman: Dawn of Justice', \n",
    "              'Pulp Fiction', 'The Godfather', 'The Shawshank Redemption', 'The Lord of the Rings: The Fellowship of the Ring',  \n",
    "              'Harry Potter and the Chamber of Secrets', 'Star Wars', 'The Hobbit: The Battle of the Five Armies',\n",
    "              'Iron Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1668751524302,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "G0UfKTONV22K",
    "outputId": "3c1328de-615a-49a3-9b54-51c764ab1644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Minions\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'movie_recommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m movie \u001b[38;5;129;01min\u001b[39;00m popular_movies:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mMovie:\u001b[39m\u001b[33m'\u001b[39m, movie)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTop 5 recommended Movies:\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mmovie_recommender\u001b[49m(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'movie_recommender' is not defined"
     ]
    }
   ],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmdn6yPYHMCo"
   },
   "source": [
    "# Rekomendasi Film dengan Penyematan\n",
    "\n",
    "Kita menggunakan fitur normalisasi berbasis hitungan di bagian sebelumnya. Bisakah kita menggunakan penyematan kata dan kemudian menghitung kesamaan film? kita pasti bisa! Di sini kita akan menggunakan model FastText dan melatihnya di korpus kita.\n",
    "\n",
    "Model FastText pertama kali diperkenalkan oleh Facebook pada tahun 2016 sebagai perpanjangan dan seharusnya merupakan peningkatan dari model vanilla Word2Vec. Berdasarkan makalah asli berjudul 'Enriching Word Vectors with Subword Information / Memperkaya Vektor Kata dengan Informasi Subword' oleh Mikolov et al. yang merupakan bacaan yang bagus untuk mendapatkan pemahaman mendalam tentang cara kerja model ini. Secara keseluruhan, FastText adalah kerangka kerja untuk mempelajari representasi kata dan juga melakukan klasifikasi teks yang kuat, cepat, dan akurat. Framework ini bersumber terbuka dari Facebook di GitHub dan mengklaim memiliki yang berikut ini.\n",
    "- Vektor kata bahasa Inggris terkini.\n",
    "- Vektor kata untuk 157 bahasa dilatih di Wikipedia dan Perayapan.\n",
    "- Model untuk identifikasi bahasa dan berbagai tugas yang diawasi.\n",
    "\n",
    "Meskipun saya belum mengimplementasikan model ini dari awal, berdasarkan makalah penelitian, berikut adalah apa yang saya pelajari tentang cara kerja model tersebut. Secara umum, model prediktif seperti model Word2Vec biasanya menganggap setiap kata sebagai entitas yang berbeda (mis. `di mana`) dan menghasilkan penyematan padat untuk kata tersebut. Namun hal ini menjadi batasan serius dengan bahasa yang memiliki kosakata besar dan banyak kata langka yang mungkin tidak banyak muncul di kumpulan yang berbeda. Model Word2Vec biasanya mengabaikan struktur morfologi setiap kata dan menganggap kata sebagai satu kesatuan. Model FastText menganggap setiap kata sebagai Bag of Character n-gram. Ini juga disebut sebagai model subword di koran.\n",
    "\n",
    "Kami menambahkan simbol batas khusus < dan > di awal dan akhir kata. Hal ini memungkinkan kita untuk membedakan prefiks dan sufiks dari rangkaian karakter lainnya. Kami juga menyertakan kata w itu sendiri dalam himpunan n-gramnya, untuk mempelajari representasi setiap kata (selain karakter n-gramnya). Mengambil kata `di mana` dan n=3 (tri-gram) sebagai contoh, itu akan diwakili oleh karakter n-gram: `<wh, whe, her, ere, re>` dan urutan khusus `<where >` mewakili seluruh kata. Perhatikan bahwa urutan , yang sesuai dengan kata `<her>` berbeda dengan tri-gram `her` dari kata `where`.\n",
    "\n",
    "Di sini kami memanfaatkan `gensim` untuk membuat embedding kami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "V5_7kZA6V33t"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastText\n\u001b[32m      3\u001b[39m tokenized_docs = [doc.split() \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m norm_corpus]\n\u001b[32m      4\u001b[39m ft_model = FastText(tokenized_docs, window=\u001b[32m30\u001b[39m, min_count=\u001b[32m2\u001b[39m, workers=\u001b[32m4\u001b[39m, sg=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "tokenized_docs = [doc.split() for doc in norm_corpus]\n",
    "ft_model = FastText(tokenized_docs, window=30, min_count=2, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwV4oV_cHfM2"
   },
   "source": [
    "# Hasilkan penyematan tingkat dokumen / Word Embedding\n",
    "\n",
    "Model penyematan kata (word embedding) memberi kita penyematan untuk setiap kata, bagaimana kita dapat menggunakannya untuk tugas ML\\DL hilirisasi? salah satu caranya adalah dengan meratakannya atau menggunakan model sekuensial. Pendekatan yang lebih sederhana adalah dengan rata-rata semua penyematan kata untuk kata-kata dalam dokumen dan menghasilkan penyematan tingkat dokumen dengan panjang tetap (fixed-length document level emebdding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BhPCV1CtV9G5"
   },
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        \n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model.wv[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "        return feature_vector\n",
    "\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1668752106985,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "nFqOWpbdV-Ba",
    "outputId": "6f0da3ed-6d5f-4d18-9642-bd45215fa812"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m doc_vecs_ft = averaged_word2vec_vectorizer(\u001b[43mtokenized_docs\u001b[49m, ft_model, \u001b[32m100\u001b[39m)\n\u001b[32m      2\u001b[39m doc_vecs_ft.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenized_docs' is not defined"
     ]
    }
   ],
   "source": [
    "doc_vecs_ft = averaged_word2vec_vectorizer(tokenized_docs, ft_model, 100)\n",
    "doc_vecs_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnJmgr6WHwH4"
   },
   "source": [
    "# Dapatkan Rekomendasi Film\n",
    "\n",
    "Kami akan memanfaatkan kesamaan kosinus lagi untuk menghasilkan rekomendasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1668752108166,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "FFGFgWX3V_HT",
    "outputId": "cf488ad3-b6e3-4f4e-f5de-4c34819f46da"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m doc_sim = \u001b[43mcosine_similarity\u001b[49m(doc_vecs_ft)\n\u001b[32m      2\u001b[39m doc_sim_df = pd.DataFrame(doc_sim)\n\u001b[32m      3\u001b[39m doc_sim_df.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'cosine_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "doc_sim = cosine_similarity(doc_vecs_ft)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1668752108167,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "DgoeV1VQWAAx",
    "outputId": "165e8af8-da05-410f-ce83-1c67477ea922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Minions\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'movie_recommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m movie \u001b[38;5;129;01min\u001b[39;00m popular_movies:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mMovie:\u001b[39m\u001b[33m'\u001b[39m, movie)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTop 5 recommended Movies:\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mmovie_recommender\u001b[49m(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'movie_recommender' is not defined"
     ]
    }
   ],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKsyeNETQ3CwZB7j+nhbFn",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
